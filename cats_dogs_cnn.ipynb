{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classificação de Gatos e Cachorros com CNN\n",
        "\n",
        "Este notebook implementa um modelo de classificação de imagens usando TensorFlow/Keras para distinguir entre gatos e cachorros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir caminhos do dataset\n",
        "base_path = 'farmtech_yolo_project/dataset'\n",
        "train_path = os.path.join(base_path, 'train/images')\n",
        "test_path = os.path.join(base_path, 'test/images')\n",
        "valid_path = os.path.join(base_path, 'valid/images')\n",
        "\n",
        "# Verificar se os diretórios existem\n",
        "print(f\"Train path exists: {os.path.exists(train_path)}\")\n",
        "print(f\"Test path exists: {os.path.exists(test_path)}\")\n",
        "print(f\"Valid path exists: {os.path.exists(valid_path)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para carregar imagens e labels\n",
        "def load_images_and_labels(images_path, img_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Carrega imagens do diretório e cria labels baseado no nome do arquivo\n",
        "    cat.*.jpg -> label 0\n",
        "    dog.*.jpg -> label 1\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    # Listar todos os arquivos no diretório\n",
        "    files = sorted(os.listdir(images_path))\n",
        "    \n",
        "    for filename in files:\n",
        "        if filename.endswith('.jpg'):\n",
        "            # Carregar e processar a imagem\n",
        "            img_path = os.path.join(images_path, filename)\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize(img_size)\n",
        "            img_array = np.array(img)\n",
        "            \n",
        "            # Garantir que a imagem está em RGB (3 canais)\n",
        "            if len(img_array.shape) == 2:  # Se for grayscale\n",
        "                img_array = np.stack([img_array] * 3, axis=-1)\n",
        "            \n",
        "            images.append(img_array)\n",
        "            \n",
        "            # Criar label baseado no nome do arquivo\n",
        "            if filename.startswith('cat'):\n",
        "                labels.append(0)  # Gato = 0\n",
        "            elif filename.startswith('dog'):\n",
        "                labels.append(1)  # Cachorro = 1\n",
        "    \n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "print(\"Função de carregamento criada!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar o dataset\n",
        "print(\"Carregando dataset...\")\n",
        "\n",
        "train_images, train_labels = load_images_and_labels(train_path)\n",
        "test_images, test_labels = load_images_and_labels(test_path)\n",
        "valid_images, valid_labels = load_images_and_labels(valid_path)\n",
        "\n",
        "print()\n",
        "print(f\"Train images shape: {train_images.shape}\")\n",
        "print(f\"Train labels: {len(train_labels)}\")\n",
        "print(f\"Train labels content: {train_labels}\")\n",
        "print()\n",
        "print(f\"Test images shape: {test_images.shape}\")\n",
        "print(f\"Test labels: {len(test_labels)}\")\n",
        "print()\n",
        "print(f\"Valid images shape: {valid_images.shape}\")\n",
        "print(f\"Valid labels: {len(valid_labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salva as classes\n",
        "class_names = ['Cat', 'Dog']\n",
        "print(f\"Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exibir algumas imagens do dataset de treino\n",
        "plt.figure(figsize=(12, 8))\n",
        "num_images = min(20, len(train_images))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar os dados\n",
        "# Toda imagem é representada por uma matriz de pixels que vai de 0 a 255\n",
        "# Redes neurais funcionam melhor com valores de 0 a 1 ou -1 a 1.\n",
        "# Então vamos dividir os valores da matriz por 255 para ter uma escala de 0 a 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "valid_images = valid_images / 255.0\n",
        "\n",
        "print(\"Imagens normalizadas!\")\n",
        "print(f\"Train images range: [{train_images.min():.2f}, {train_images.max():.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelo utilizando TensorFlow/Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição da semente de aleatoriedade\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define o modelo CNN (Convolutional Neural Network)\n",
        "model = keras.Sequential([\n",
        "    # Camada de entrada\n",
        "    keras.layers.Input(shape=(128, 128, 3)),\n",
        "    \n",
        "    # Primeira camada convolucional\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Segunda camada convolucional\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Terceira camada convolucional\n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    # Achatamento\n",
        "    keras.layers.Flatten(),\n",
        "    \n",
        "    # Camadas densas\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),  # Dropout para evitar overfitting\n",
        "    \n",
        "    # Camada de saída (2 classes: cat, dog)\n",
        "    keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(\n",
        "    optimizer='adam',  # Algoritmo de otimização\n",
        "    loss='sparse_categorical_crossentropy',  # Função de perda para classificação\n",
        "    metrics=['accuracy']  # Métrica para avaliar\n",
        ")\n",
        "\n",
        "print(\"Modelo criado e compilado!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# O que tem neste modelo? Exibir a arquitetura do modelo\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Treinamento do modelo\n",
        "print(\"Iniciando treinamento...\")\n",
        "history = model.fit(\n",
        "    train_images, \n",
        "    train_labels, \n",
        "    epochs=20,\n",
        "    validation_data=(valid_images, valid_labels),\n",
        "    batch_size=8\n",
        ")\n",
        "print(\"Treinamento concluído!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Avaliação do modelo com o conjunto de teste\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print()\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar histórico de treinamento\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Acurácia\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Acurácia durante o Treinamento')\n",
        "plt.grid(True)\n",
        "\n",
        "# Perda\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Perda durante o Treinamento')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fazer predições em algumas imagens de teste\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Visualizar predições\n",
        "plt.figure(figsize=(12, 8))\n",
        "num_images = min(8, len(test_images))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i])\n",
        "    \n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = test_labels[i]\n",
        "    \n",
        "    # Cor verde se correto, vermelho se errado\n",
        "    color = 'green' if predicted_label == true_label else 'red'\n",
        "    \n",
        "    plt.xlabel(f\"Pred: {class_names[predicted_label]}\\nTrue: {class_names[true_label]}\", \n",
        "               color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar o modelo treinado\n",
        "model_save_path = 'cats_dogs_model.keras'\n",
        "model.save(model_save_path)\n",
        "print(f\"Modelo salvo em: {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumo do Modelo\n",
        "\n",
        "Este notebook implementou um modelo CNN (Convolutional Neural Network) para classificação de imagens de gatos e cachorros usando TensorFlow/Keras.\n",
        "\n",
        "### Arquitetura do Modelo:\n",
        "- **Camadas Convolucionais**: 3 camadas conv2D com filtros 32, 64 e 128\n",
        "- **Pooling**: MaxPooling após cada convolução para redução dimensional\n",
        "- **Camada Densa**: 128 neurônios com ativação ReLU\n",
        "- **Dropout**: 0.5 para regularização\n",
        "- **Saída**: 2 neurônios (cat/dog) com ativação softmax\n",
        "\n",
        "### Dataset:\n",
        "- **Training**: 64 imagens (32 gatos + 32 cachorros)\n",
        "- **Validation**: 8 imagens (4 gatos + 4 cachorros)\n",
        "- **Test**: 8 imagens (4 gatos + 4 cachorros)\n",
        "\n",
        "### Pré-processamento:\n",
        "- Redimensionamento para 128x128 pixels\n",
        "- Normalização (valores entre 0 e 1)\n",
        "- Conversão para RGB (3 canais)\n",
        "\n",
        "### Parâmetros de Treinamento:\n",
        "- **Epochs**: 20\n",
        "- **Batch Size**: 8\n",
        "- **Optimizer**: Adam\n",
        "- **Loss Function**: Sparse Categorical Crossentropy\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
